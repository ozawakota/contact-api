# contact-api
apiでコンタクトフォーム（オブザービリティ）を構築


## URL
https://fastapi-service-1007971663371.asia-northeast1.run.app/

## GCP > Cloud Run > サービス
fastapi-service

## 管理画面
https://console.cloud.google.com/cloud-build/builds?referrer=search&authuser=0&project=cobalt-howl-278500&supportedpurview=project

## CI/CD パイプライン（cloudbuild.yaml）

`cloudbuild.yaml` は **Google Cloud Build** を使った自動デプロイの設定ファイルです。
コードをプッシュすると、以下の3ステップが自動で実行されます。

```
ステップ1: ビルド → ステップ2: プッシュ → ステップ3: デプロイ
```

### ステップ1: Docker イメージのビルド

```
Dockerfile の場所 : backend/db-backup/docker/Dockerfile
ビルドコンテキスト: ./backend（appフォルダなどを参照できるようにするため）
イメージ名        : asia-northeast1-docker.pkg.dev/{PROJECT_ID}/contact-api/fastapi-app
```

> `./backend` をコンテキストに指定することで、Dockerfile 内から `app/` などのフォルダを
> 正しく参照できるようにしています。

### ステップ2: Artifact Registry へのプッシュ

ビルドしたイメージを **asia-northeast1（東京）** の Artifact Registry に登録します。

### ステップ3: Cloud Run へのデプロイ

| 項目 | 値 |
|---|---|
| サービス名 | `fastapi-service` |
| リージョン | `asia-northeast1`（東京） |
| プラットフォーム | マネージド（サーバーレス） |
| 認証 | 不要（`--allow-unauthenticated`） |

### ログ設定

`CLOUD_LOGGING_ONLY` を指定しており、ビルドログは **Cloud Logging** にのみ出力されます
（Cloud Storage へのログ保存は行いません）。

---

## LLM学習

> 基礎
* LLMエンジニアの役割
* ChatGPT・Claudeという二大モデルの特性を理解

> 実践
* プロンプト、RAG、エージェントの3つの核となる技術

> 開発
* OpenAI APIとAnthropic APIを使った具体的なコード例

> 応用
* LLMOps、評価、デプロイ、
* LLMエンジニアの論理的、法的責任：著作権とデータプライバシー
* 個人識別情報のマスキング（匿名化）


### コンテキストウィンドウ
LLMが一度にい処理できる入力と出力のトークン数の上限


### モデル選定の基準
* コスト
 > トラフィックの量
 > 応答速度
* 性能
 > 複雑な推論
* 安全性
 > 論理的配慮

```
* GPT-o/GPT : 汎用性、速度、マルチモーダル、外部ツール連携の成熟度を重視する場合

* Claude . Sonnet/Ops : 長文処理、安全性、論理的配慮、複雑な推論の一貫性を重視する場合
```

## 基本構造
* 役割 : LLMにどんな専門家になってほしいか
* タスク : LLMに実行してほしい具体的な作業
* 制約 : 出力形式、長さ、使用すべき情報源、LLMの応答を制限するルール

## 構造化出力の強制 (重要)

Json,XML形式での出力で、後続のプログラムの構造化を促せます

## プロンプトインジェクションの対策とガードレールの設計

> プロンプトインジェクションの対策
* 分離 : ユーザー入力とシステムプロンプトを明確に分離。LLMに
「ユーザー入力よりもシステムプロンプトの指示を優先すること」を明示的に指示します
＊サニタイズ : ユーザー入力から、プロンプトインジェクションに利用されやすいキーワードをフィルタリングします。

* ガードレール : LLMの出力に対して、有害なコンテンツや機密情報が含まれていないかをチャックする外部フィルタリング層を設定します。

## 究極の応用テクニック

* Tree-of-Thought
複数の異なる推論パスを生成させ、それぞれのパスを評価し、元も有望なパスを選択して探索を進める手法
例）複雑なパズル、戦略げーむ、創造的な問題解決など
* Self-Refinement
LLMに初回の回答を生成させた後、その回答を批判的に評価し、改善させるプロセスを繰り返す手法
例）エッセイの執筆、コードのデバック、複雑なデータ分析のレポート作成

# RAG(検索拡張生成)による知識ベース構築
外部の知識ベースから関連情報を検索し、その情報をLLMへのプロンプトに含めて応答を生成させる技術です。

> LLMの重み（パラメータ）を変更せず、外部知識ベースを更新することで、知識を最新に保ちます。

* 第一歩 : 埋め込みモデルの選定とベクトル化
ドキュメントを数値ベクトルに変換する埋め込み(Embedding)

注） ファインチューニングとの違い：ファインチューニングはLLMの重みを変更して、特定のタスクやドメインを特化させます。知識の再学習により、コストが高くなります。

埋め込みモデル : OpenAIのtext-embedding3-largeやBGE (BAAI General Embedding)などが利用できます

> ベクトル化

ドキュメントを埋め込みモデルに通し、ベクトルデータベースに保存します。

* ベクトルデータベースの選定と構築
Chroma , Milvus, pgvector , Pinecone(マネージドサービス)
** 選定基準はスケーラビリティ、検索速度（レイテンシ）、コスト、クラウドサービスとしての提携形態

> チャンキング戦略
* 固定サイズチャンキング : 文脈が途切れるリスクがあります
* セマンティックチャンキング : 文書構造や意味的なまとまりをチャンク間で一部のテキストを重複させます

> フレームワーク
RAGの実装を簡素化するための主要なフレームワークとして、LlamaIndexとLangChainがあります。

* LlamaIndex
データ接続、インデックス作成、クエリ実行に特化しており、BAGパイプラインの構築に優れています。
* LangChain
LLMアプリケーションのコンポーネーション（LLM、プロンプト、チェイン、エージェント）をモジュール化し、複雑なワークフローを構築するための汎用的なフレームワークです。

> RAGの課題
* 検索ノイズとハルシネーションの再発
RAGはハルシネーションを軽減しますが、完全に防ぐことはできません。
* 検索ノイズ : 検索結果に質問と無関係なドキュメントが含まれていることで、LLMが誤った情報に基づいて応答すを生成するリスク

*対策*
検索結果の数を制限する、再ランキングを導入する、LLMに「提供されたコンテンツに情報がない場合は、その旨を伝えること」を明示する

> RAGの応用
* ハイブリッド検索とReranking戦略
ハイブリッド検索はベクトル検索とキーワード検索を組み合わせる手法です。
Rerankingは、検索で取得された上位N件のドキュメントを、より高性能なモデルで再評価し、KKMに渡すドキュメントの順序を最適化するプロセスです。

**Reranker モデル**
Cohere Rerankにユーザーの質問と各ドキュメントのペアを入力し、関連どをより正確にスコアリングさせます。

**Query Transformation (クエリ書き換え)**
ユーザーの曖昧な質問を、AIが一度「検索しやすい言葉」に書き換えてからDBに投げます。

> 評価と改善（RAGASなど）

「なんとなく良くなった」ではなく、数値で評価することも重要です。
RAGAS (RAG Assessment): 「回答の正確性」「検索結果の妥当性」などをAIが自動でスコアリングしてくれるフレームワークです。


# Function Callingとエージェント開発の基礎：LLMにツールを使わせる技術

LLMは以下のことが苦手です。

* 最新情報の取得（例：今日の天気、株価、最新ニュース）
* 正確な計算（例：複雑な数学、桁数の多い計算）
* 外部システムの操作（例：メールを送る、カレンダーに予定を入れる）

これらを解決するために、「計算が必要なら電卓を使え」「天気が知りたいなら検索APIを叩け」と指示するのがこの技術こと

> 複雑なエージェントのツール設計原則
* 単一責任の原則
* 明確な説明 (Despription)
* 厳密なスキーマ
* Advanced Agent Design : マルチエージェントフレームワーク (Microsoft AutoGen)

> Microsoft AutoGenと同じように、複数のAIを連携させて仕事をさせる「マルチエージェント・フレームワーク」はいくつか存在します

* CrewAI（クルーAI）: 記事の執筆、マーケティング戦略の立案、リサーチ業務など、プロセスが比較的はっきりしている仕事。
* LangGraph : 信頼性が求められる業務システム、複雑な条件分岐があるRAG、失敗が許されない自動化タスク。
* PydanticAI : 既存のWebアプリへの組み込み、APIサーバーとしての運用、型安全な開発。

## エージェントの記憶と状態管理

* 短期記憶 : (message配列)
* 長期記憶 : RAGで利用するベクトルデータベースを記憶ストアとして利用する過去の対話をベクトル化し、関連性の高い記憶を検索してプロンプトに組み込みます。

# 開発編 実践的なAPIの活用とコード例

